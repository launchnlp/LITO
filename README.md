This repository provides the code and datsets for the **Enhanced Language Model Truthfulness
with Learnable Intervention and Uncertainty Expression** paper. We introduce LITO, a context-aware intervention method that improves truthfulness in language models and is equipped wtih refusal ability when unable to identify highly confident truthful responses.
## Installation
In this the root folder of this repo, run the following commands to set things up.
```
conda env create -f environment.yaml
conda activate lito
pip install git+https://github.com/davidbau/baukit
````

## Collect ITI Features
For each of the datasets, collect their corresponding ITI features for probe training. For example, to train linear probes for Llama2_Chat_7B model on the NQ dataset, run:
```
python collect_iti_activations.py llama2_chat_7B --dataset_name nq
```
This will provide the activations for each dataset and each model in order to find directions uisng the iti method. 


## Collect Hidden States for training and evaluating LITO
For each model, each dataset, each mode (train/test), and each of the 5 different intensity values (alpha), the following script needs to be ran:

```
python collect_hidden_states.py gpt2_xl --dataset_name trivia_qa --alpha 15 --mode train
```

## LITO Training and Evaluation

To train and then test LITO after collecting the responses, their corresponding hidden states, and confidence values, you can train/test LITO by running the following command: (here we train LITO on the responses generated by Llama2_Chat_7B model for the NQ task)

```
python classification.classifier_rnn_binary_main llama2_chat_7B --dataset_name nq --mode train
```

Please explore other hyper-parameters in each of the above scripts. 

## Contact
In case of any issues or questions, please send an email to ```farimaf (at) umich (dot) edu```.
